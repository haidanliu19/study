{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Theano를 통한 머신러닝 구현.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9waaSvJo32R"
      },
      "source": [
        "https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=103\n",
        "\n",
        "\n",
        "\n",
        "# T 아카데미 \n",
        "인공지능을 위한 머신러닝 알고리즘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4ux8tWToP8P"
      },
      "source": [
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz3kHCMGofMJ"
      },
      "source": [
        "rng = np.random\n",
        "\n",
        "N = 400 # 데이터 샘플 개수\n",
        "feats = 784\n",
        "D = (rng.randn(N,feats).astype(np.float32), rng.randint(size= N, low=0, high=2).astype(np.float32))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH1o6cFhsdMx"
      },
      "source": [
        "training_steps = 10000 # epoch 훈련 과정 몇번 하는지 "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDJ3Fkvno8kI",
        "outputId": "7f992de7-192d-4bbf-e9d1-c28e085fe3fd"
      },
      "source": [
        "x = T.matrix('x') # 데이터의 특징 모델의 입력이 되는 특징값\n",
        "y = T.vector('y') # 각 데이터의 레이블 출력값 \n",
        "# 다층 퍼셉트론은 지도학습 \n",
        "\n",
        "# 모델의 파라미터 \n",
        "# 입력과 출력에 대한 가중치 \n",
        "w_1 = theano.shared(rng.randn(784, 300), name ='w1')\n",
        "b_1 = theano.shared(np.zeros(300), name='b1')\n",
        "w_2 = theano.shared(rng.randn(300), name ='w2')\n",
        "b_2 = theano.shared(0., name='b2') # 1차원 0 아니면 1 300크기의 vector가 되고 bias 는 scaler값이 된다. \n",
        "\n",
        "print(w_1.get_value(), b_1.get_value())\n",
        "print(w_2.get_value(), b_2.get_value())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.8687659  -1.51067031 -1.70067303 ... -1.07564025 -0.08261203\n",
            "  -0.19634284]\n",
            " [ 0.74611918 -1.11576205  1.29345377 ...  1.4466958   1.33449298\n",
            "   1.69581702]\n",
            " [ 0.69841687  1.32222191 -0.77112109 ...  1.63541805  0.59407193\n",
            "   0.22644279]\n",
            " ...\n",
            " [ 0.04274498  0.17358673 -0.76990259 ... -0.64510678 -0.37099839\n",
            "  -0.5060321 ]\n",
            " [ 0.29141284  0.19649283 -0.32044523 ... -1.29019951 -0.5457147\n",
            "   1.98074687]\n",
            " [ 1.01156049  0.10408242  0.47851609 ...  1.24988563  0.79222529\n",
            "   0.2285402 ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 0.43534925  1.36387463  1.41588806  0.52040924 -0.78126599 -2.60465432\n",
            " -0.80627747  0.71645179 -1.16426921  0.55535417 -0.36043277  0.00856269\n",
            "  1.98672479  0.33912899 -2.0820961   0.96497397  0.02570658 -0.07682643\n",
            " -1.24677309  0.60090126  0.33356743 -1.31553004  0.63739821 -0.54704373\n",
            " -1.72816616 -0.85189263  1.32674339 -1.36696024  2.14618897 -2.5384936\n",
            " -0.44211353 -1.53040957  0.35288374 -0.64001772 -0.11620204  0.69804142\n",
            " -0.38387389 -0.35777198 -0.48111709  1.42495546 -0.18909235  1.04434733\n",
            "  1.01049001 -0.64927059 -0.14262649  1.44429523  0.48141019 -0.61758184\n",
            "  0.74010233 -0.40908883 -0.70690054  2.48330274  0.53616949 -0.5363394\n",
            " -1.06710962 -1.6814264  -0.79816965 -0.82919368  0.11739381 -0.84010253\n",
            "  0.17742244  0.72349223  1.29013902 -0.46079044 -0.21568378  2.22213235\n",
            "  0.28221174 -0.38380104  0.26632    -1.15405231  0.70533443 -1.04269266\n",
            "  0.24238174  0.57334676  0.49377503  0.0270557   2.11405122 -0.22599274\n",
            " -1.22215758 -1.40247851 -0.08380578 -0.76232688 -0.41069377 -0.43773944\n",
            " -0.15022167  1.42575655 -0.7538746  -1.14989939  0.60804046 -1.67675357\n",
            "  1.05136667 -1.55529349  0.24618324 -1.73741005 -0.26075345  0.83960815\n",
            " -0.77285103 -0.26777296  0.65137837  1.16876134  1.39091412  1.48512813\n",
            "  1.87762686  1.28851124 -1.6519177   0.78188543  1.79216123 -0.33871138\n",
            " -1.7216955  -0.10392854  0.53142586  0.56039623 -1.10041217  0.24371528\n",
            " -1.00362181 -1.31855946  0.75063334 -0.98026402  0.41798062 -3.22974983\n",
            "  0.13565723  0.93251178 -2.45331597 -0.33231013  0.94502449  1.04754691\n",
            " -0.79692941  0.61773997  0.44672419 -0.74828473 -0.14370954 -0.69054473\n",
            " -0.22174648  1.66754422  1.57757901 -0.30769976 -0.96714503  0.19076494\n",
            " -1.040232    0.80563389  1.348292   -0.15206851  0.29959737  0.91790416\n",
            "  0.18597609 -0.33513219 -2.10717995  0.74777063  1.14073847  0.9036575\n",
            "  1.01440689  0.10370098 -0.91937274  0.49166213  0.69973425  0.77568506\n",
            " -0.20042883 -1.28553147  0.00576606  1.03668906  0.03264225  0.14727918\n",
            " -0.40276044  0.99491747 -0.43057018 -0.93936573 -0.06085913  1.07383616\n",
            "  1.18999854  0.98047049  0.91526563 -1.3636122  -1.49000045 -0.3978594\n",
            " -1.23557813 -0.26731696  0.22346189 -0.65200237  2.29790681  0.07721303\n",
            " -0.94492825 -0.44826167 -0.66443472  0.15794606  1.37868716 -1.69762042\n",
            " -1.37724922  0.37309803  0.0638728   1.13828588 -0.62005654 -0.86590511\n",
            "  0.38983468 -0.15367104 -0.71151003  0.21186722  0.13905452  0.38398095\n",
            "  0.96725198  0.0272267   0.48619947  0.51643402  1.41288855  0.19365298\n",
            " -0.46191369  2.22378024  1.02587088 -2.03171984  0.58402188  1.03881045\n",
            "  0.17202312 -0.5191923   0.02980779  0.91889582  0.22024014 -1.3740057\n",
            "  0.0446421   1.17547834  0.30685532  0.4831941  -0.27568173 -1.83830556\n",
            " -1.41331297 -1.9110138   0.53694701  0.00935519  1.60505477  0.36106191\n",
            "  1.197416   -1.00167801  0.51908388 -0.56324762  0.05971856  0.12108881\n",
            "  1.75181079 -0.3355436   0.7239935  -1.52436961 -0.64693246 -0.70101361\n",
            " -2.29622288  0.10962651  0.11428264  1.87832401 -0.86829046  0.65120002\n",
            "  0.53168487 -0.02575943  1.79185907 -0.8753895   0.72767532  2.69359851\n",
            " -1.13029004 -0.71472058 -0.80688123  0.16397378 -0.23088505  0.63120283\n",
            " -0.37054499 -0.8244823   0.57139353  1.02040253  0.40061123 -0.36797293\n",
            " -0.25881698 -1.20473289  0.87320286  0.80032113  0.39944019 -2.16896735\n",
            "  0.7457753   0.50109611 -1.70936713 -1.12909007 -1.05440957  0.11982942\n",
            " -2.48703851  0.26393201 -0.76974795 -1.81071932  0.04055879  0.5093668\n",
            "  0.83403401 -1.75181732 -0.52347894 -0.26423883 -1.07672285 -2.20295553\n",
            " -0.14648136 -0.62707736 -0.23458968 -0.4127061  -0.50600379 -0.70827842\n",
            " -2.1489415   0.8623752   1.84850624 -1.29763035 -0.29538241 -0.42971349] 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Izx9OR3poa1"
      },
      "source": [
        "p_1 = T.nnet.sigmoid(T.dot(T.nnet.sigmoid(T.dot(x,w_1)+b_1), w_2) +b_2)\n",
        "prediction = p_1 >0.5\n",
        "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # cross entropy\n",
        "cost = xent.mean() + 0.01 * ( (w_1 ** 2).sum()+ (w_2 ** 2).sum() +(b_1 ** 2).sum() + (b_2 ** 2).sum()) # regularization 파라미터가 크지 않도록 결정을 한다.\n",
        "gw_1,gb_1, gw_2, gb_2 = T.grad(cost,[w_1,b_1,w_2,b_2]) # 손실 함수에 대한 파라미터 의 변화량  미분을 한다. 각각의 파라미터에 대해서 미분"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDC_N-loq0qB",
        "outputId": "7af935a7-bd41-4b19-e27f-b055df9903f0"
      },
      "source": [
        "train = theano.function(inputs=[x,y], outputs=[prediction, xent], \n",
        "                        updates = {w_1:w_1-0.1*gw_1, b_1:b_1-0.1*gb_1,\n",
        "                                   w_2:w_2-0.1*gw_2, b_2: b_2- 0.1*gb_2}) # 학습률 0.1\n",
        "\n",
        "predict = theano.function(inputs=[x], outputs=prediction)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (collections.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHSkqc3Wq3Rx",
        "outputId": "9fd76fe6-4499-4732-aa62-92b727913d65"
      },
      "source": [
        "for i in range(training_steps):\n",
        "    pred, err = train(D[0], D[1]) # D[0] 데이터의 특징 D[1] l레이블 값\n",
        "\n",
        "print(\"Final model:\")\n",
        "print(w_1.get_value(), b_1.get_value())\n",
        "print(w_2.get_value(), b_2.get_value())\n",
        "print(\"target values for D:\", D[1]) # 실제값\n",
        "print(\"predictions on D:\", predict(D[0])) # 모델의 예측값 "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final model:\n",
            "[[ 0.0007124   0.00080121  0.00012721 ...  0.00037742  0.00029325\n",
            "   0.00017759]\n",
            " [-0.00778058 -0.00868379 -0.00144233 ... -0.00423075 -0.00330339\n",
            "  -0.00201059]\n",
            " [ 0.00254089  0.00285478  0.0004579  ...  0.00135391  0.00105345\n",
            "   0.00063895]\n",
            " ...\n",
            " [-0.00455433 -0.00505296 -0.00086348 ... -0.00251783 -0.00197113\n",
            "  -0.00120281]\n",
            " [-0.00585703 -0.00656257 -0.00106707 ... -0.00314577 -0.00245086\n",
            "  -0.00148842]\n",
            " [-0.00647177 -0.00726165 -0.00117182 ... -0.0034607  -0.00269415\n",
            "  -0.00163491]] [ 1.88339321e-04  2.55437654e-04  3.21271364e-06  6.18001412e-05\n",
            "  8.21359116e-06 -2.81847388e-04  4.08766308e-05  3.13005561e-05\n",
            " -2.33957564e-04  9.18008758e-06 -5.31863356e-05 -8.92256744e-06\n",
            "  2.70599361e-04  5.34757030e-06 -3.09872272e-04  2.97659896e-04\n",
            " -1.20765765e-06 -1.12639842e-05 -1.23231105e-04  1.85492938e-04\n",
            "  9.57864706e-06 -1.02065736e-06  3.58801251e-06 -6.75415730e-06\n",
            " -5.37243840e-05 -9.32686719e-05  1.82737467e-04 -2.48859290e-04\n",
            "  1.31128014e-04 -2.43496243e-04  1.84370930e-06 -1.27521590e-05\n",
            " -2.97684656e-06 -1.69185617e-05 -2.81357121e-05  3.18792418e-04\n",
            " -1.57065923e-05 -9.29106577e-06  1.47122754e-07  9.62133102e-05\n",
            "  1.21874681e-04  3.57638121e-05  7.10974701e-05 -1.15199512e-04\n",
            "  1.55850397e-05  1.36420197e-04  8.72961221e-05 -1.34725666e-05\n",
            "  9.18370536e-07 -2.14772077e-04 -1.68118946e-04  8.68433109e-05\n",
            "  1.14656853e-04 -7.20717093e-05 -1.57917179e-04 -2.17114775e-04\n",
            " -4.92241758e-05 -2.48329240e-04 -3.54036052e-05 -6.52705144e-05\n",
            " -2.51667479e-05  2.02844223e-04  4.37476239e-04 -4.32176890e-05\n",
            " -4.89278267e-06  3.03230389e-04  1.56859915e-05 -8.07799367e-05\n",
            " -8.12302635e-05 -3.10299151e-07  8.05593908e-05 -1.05831646e-04\n",
            "  9.78759954e-05  1.24725940e-04 -9.20793850e-07  2.17967531e-05\n",
            "  3.71830421e-04 -8.96159282e-05 -2.51531026e-04 -4.80612727e-05\n",
            " -1.28679454e-06 -8.73274400e-06  6.20728608e-05 -4.92561404e-05\n",
            "  9.08784657e-07  2.64308793e-04 -1.79857899e-04 -3.24478280e-04\n",
            "  7.32900567e-05  1.11075996e-05  3.88285763e-05 -3.94854589e-04\n",
            " -5.49333105e-06 -3.24950717e-05  6.27030052e-06  2.16935887e-04\n",
            "  1.21466620e-07 -5.03456986e-06 -2.18538392e-06  1.21552519e-04\n",
            "  9.95425308e-06  6.12199095e-05  9.17219389e-05  1.06082623e-04\n",
            " -2.21908505e-04  1.44438565e-04  2.72864442e-04 -1.05768430e-04\n",
            " -4.34347982e-04  9.53111989e-07  4.27423242e-05  5.61920303e-04\n",
            " -1.62065467e-04 -1.11279596e-06 -8.29802399e-05 -2.17327014e-04\n",
            "  1.16815274e-05 -1.08419524e-05 -1.11103968e-06 -3.21175087e-04\n",
            " -8.89379692e-05  2.63658819e-04 -1.57295279e-04 -1.93890337e-05\n",
            "  1.58560906e-05  8.81763313e-05 -2.27430664e-05 -1.07364373e-05\n",
            "  1.17513247e-06 -1.55192292e-04  2.17868215e-04 -1.46571247e-05\n",
            " -2.62783358e-05  2.82825390e-04  2.99813647e-05  6.58063930e-06\n",
            " -2.74805075e-04 -4.36349828e-06 -1.14804289e-04  1.83154528e-04\n",
            " -8.26760945e-07 -1.01617797e-05  3.01997466e-05  1.04154724e-05\n",
            "  8.98341235e-05 -2.17215375e-05 -2.91608085e-04 -1.48570526e-06\n",
            "  2.44334237e-05  1.69605792e-04  3.46476524e-06  1.07347945e-05\n",
            " -4.94388678e-05 -4.86249450e-06  2.49858657e-06  1.41698986e-05\n",
            " -1.53309856e-05 -5.53806402e-07  6.25657136e-05  4.86325689e-05\n",
            "  1.68021699e-05  1.71896651e-04 -1.94037414e-05  1.27050790e-04\n",
            "  8.16696181e-07 -3.08488997e-05 -1.84030916e-05  9.68643255e-05\n",
            "  1.35965073e-05 -1.48203931e-05 -8.18248251e-06 -1.81399081e-05\n",
            " -2.09313340e-04 -8.14140857e-05  1.87319817e-06  3.94890848e-07\n",
            "  2.65957005e-05  5.11360626e-05  1.26608945e-04  2.33402137e-06\n",
            " -2.83244535e-04  1.39023947e-05 -7.74636368e-05  3.50230614e-05\n",
            "  4.56584327e-04 -1.38503291e-06 -4.15625657e-06  8.28129300e-06\n",
            "  1.63009940e-05  2.32834583e-04 -2.02152820e-05 -1.67292532e-04\n",
            " -7.15588292e-05 -2.72063690e-05 -8.04597281e-05  8.48161891e-06\n",
            "  6.78810581e-05  4.21002148e-06  3.37372804e-04 -5.14847658e-07\n",
            "  1.24874164e-04  1.65352097e-05  8.65089700e-05 -3.20512907e-05\n",
            " -9.09700688e-05  3.20129936e-04  3.46140105e-04 -2.98452300e-05\n",
            "  4.57617590e-05  1.46814597e-04  3.58786927e-06 -9.90391336e-05\n",
            " -2.19923446e-05  2.55030782e-05  1.04945047e-06 -1.75156398e-04\n",
            " -1.35896966e-05  1.09031290e-04  2.09662489e-04 -1.35001325e-05\n",
            " -2.04474099e-05 -2.07778306e-04 -1.73731222e-05 -3.44184265e-04\n",
            "  1.19982771e-04  7.85385410e-06  1.21140454e-04 -1.99047249e-06\n",
            "  2.26463902e-04 -2.86052537e-06  7.73791990e-05 -1.85367257e-05\n",
            "  8.36858244e-06  7.39837087e-06  4.42482734e-04  2.52849296e-06\n",
            "  3.84482168e-05 -3.92088838e-05 -7.04426603e-05 -1.53440264e-04\n",
            " -2.38866793e-04 -1.33643862e-06 -1.75109704e-06 -1.92661603e-06\n",
            "  1.25304866e-05  3.09512414e-04  6.82313544e-05 -2.41320735e-04\n",
            "  1.21828852e-04 -6.93199279e-05 -6.17400805e-06  4.21009806e-04\n",
            " -2.63559795e-07  6.61114904e-05 -4.13525150e-05 -1.14427939e-05\n",
            " -5.37336684e-05 -3.12733589e-05  4.13262753e-05 -2.60023336e-04\n",
            " -1.03286332e-05  4.32024968e-05 -1.86124875e-06  2.10407775e-06\n",
            " -3.71068386e-05 -2.66767883e-06  2.94609169e-05  8.34011159e-05\n",
            " -3.21340630e-07 -2.39892853e-04 -4.89130710e-06 -1.60871819e-04\n",
            " -2.79607514e-04 -1.65786467e-06 -6.97977352e-05 -2.38280419e-07\n",
            " -1.04847849e-04  4.50898780e-05 -1.58638857e-04 -1.37876590e-04\n",
            "  9.41533755e-05  2.30248401e-04  8.93607247e-06 -3.81948717e-06\n",
            "  2.97649198e-05  2.15335704e-05 -1.44712171e-04 -2.99211050e-04\n",
            " -7.45868672e-05 -2.48728623e-04  1.49367102e-04 -1.09407645e-04\n",
            " -2.44486471e-05 -1.40337705e-04 -2.58853120e-04  1.18986834e-04\n",
            "  5.26703379e-05  3.55909569e-05  1.88369041e-05  6.04020302e-06]\n",
            "[ 0.24073278  0.26920595  0.04427702  0.16002734  0.07129867 -0.27900414\n",
            "  0.13712548  0.12387824 -0.26050518  0.07495777 -0.15120376 -0.07387175\n",
            "  0.27498564  0.05813485 -0.288962    0.28483558 -0.02275957 -0.08183682\n",
            " -0.20602911  0.23939489  0.07638539 -0.01986783  0.04712712 -0.06497739\n",
            " -0.15177217 -0.18605937  0.23808898 -0.26648927  0.21090612 -0.26436062\n",
            "  0.03123113 -0.08628975 -0.04222639 -0.09703335 -0.11874251  0.29216244\n",
            " -0.09412358 -0.07521812  0.00325328  0.18833837  0.20534347  0.13035425\n",
            "  0.16853224 -0.20101508  0.09396713  0.21397528  0.18174333 -0.08831084\n",
            "  0.01829698 -0.25244795 -0.23079576  0.18139651  0.20081503 -0.16923234\n",
            " -0.22557319 -0.25345546 -0.14689264 -0.26627987 -0.12970653 -0.16314823\n",
            " -0.11369522  0.24735991  0.32880634 -0.13988803 -0.05544758  0.28679681\n",
            "  0.09421767 -0.17649371 -0.17685429 -0.00664203  0.17646265 -0.19487391\n",
            "  0.18952323  0.20708608 -0.01822922  0.10757979  0.30937382 -0.18335369\n",
            " -0.26753821 -0.14558283 -0.0239164  -0.07316046  0.16028887 -0.14692843\n",
            "  0.01813627  0.27261186 -0.23656364 -0.29394036  0.17042915  0.08148572\n",
            "  0.13448709 -0.31625517 -0.0587808  -0.12552434  0.06284813  0.25352387\n",
            "  0.00269719 -0.05626209 -0.034866    0.20514549  0.07769055  0.15946876\n",
            "  0.18506855  0.19518968 -0.25549419  0.21848418  0.27583232 -0.1948315\n",
            " -0.32777624  0.01887629  0.13945251  0.36154485 -0.2277213  -0.02132129\n",
            " -0.17824593 -0.25354625  0.0832695  -0.08049678 -0.02129468 -0.29282668\n",
            " -0.18284181  0.27236483 -0.22524786 -0.1025327   0.09463563  0.18241278\n",
            " -0.10925709 -0.08015476  0.02238367 -0.22414378  0.25392349 -0.09147265\n",
            " -0.11562999  0.27950559  0.12184257  0.06431728 -0.27640927 -0.05224858\n",
            " -0.20076259  0.23828621 -0.01661791 -0.07825464  0.12218318  0.07924519\n",
            "  0.18366348 -0.10728835 -0.28253672 -0.02666287  0.11252977  0.23168553\n",
            "  0.04621663  0.08029295 -0.14713182 -0.05527237  0.03809853  0.09033802\n",
            " -0.09319038 -0.01157894  0.16075898  0.14637587  0.09690413  0.23282372\n",
            " -0.10256435  0.20848694  0.01655074 -0.1230414  -0.10040051  0.18880313\n",
            "  0.08879513 -0.09189351 -0.07103516 -0.09981717 -0.25007597 -0.17700225\n",
            "  0.03157218  0.00849892  0.11631897  0.14914858  0.20822216  0.03650185\n",
            " -0.27951417  0.08962449 -0.17379223  0.12931904  0.33414465 -0.02530142\n",
            " -0.05091789  0.07156454  0.09571491  0.26019057 -0.10426115 -0.2303795\n",
            " -0.16878759 -0.11720417 -0.17623555  0.07234439  0.16567719  0.0514018\n",
            "  0.29837078 -0.01081659  0.20717552  0.09627404  0.1811401  -0.12486297\n",
            " -0.18436416  0.29261687  0.30123051 -0.12148159  0.1430766   0.21978926\n",
            "  0.04712607 -0.19019832 -0.10781585  0.11443231  0.02043928 -0.23428212\n",
            " -0.08863211  0.19715655  0.25037422 -0.08838706 -0.10473701 -0.24940163\n",
            " -0.09808559 -0.3004523   0.20417388  0.06985463  0.20489131 -0.03277545\n",
            "  0.2575532  -0.04123852  0.17386893 -0.10069498  0.07190586  0.06795694\n",
            "  0.33021714  0.03838213  0.13398636 -0.13483731 -0.1678111  -0.22321502\n",
            " -0.26250125 -0.02462211 -0.03001507 -0.03206182  0.08579369  0.28898215\n",
            "  0.16599312 -0.26348987  0.20531557 -0.16681913 -0.06224324  0.3240984\n",
            " -0.00565626  0.16407011 -0.1375798  -0.08239298 -0.1517811  -0.12368978\n",
            "  0.13769321 -0.27083027 -0.07881455  0.1400157  -0.03131337  0.03413349\n",
            " -0.13204671 -0.03953855  0.1210225   0.17872471 -0.00687486 -0.26291542\n",
            " -0.05544039 -0.2271068  -0.27818284 -0.02887549 -0.16724243 -0.00511895\n",
            " -0.19420862  0.14228478 -0.22594979 -0.21465989  0.18685066  0.25912513\n",
            "  0.07406183 -0.04864437  0.12150203  0.10706318 -0.21848892 -0.28523949\n",
            " -0.17138639 -0.26643762  0.22117746 -0.19725842 -0.11241279 -0.21605196\n",
            " -0.2703804   0.20355309  0.1508004   0.13011451  0.10149334  0.06172349] 0.0001852416406257732\n",
            "target values for D: [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
            "predictions on D: [False False False  True False False  True False  True False False False\n",
            "  True  True False  True  True False  True False  True False  True  True\n",
            " False  True False False False False  True  True False False  True False\n",
            "  True False False  True False  True False  True  True False False  True\n",
            " False False  True False  True False False  True False  True  True False\n",
            " False False  True False  True False False  True  True  True False  True\n",
            " False  True False  True  True False False False  True False  True False\n",
            "  True  True False False  True False  True  True False  True  True  True\n",
            " False  True  True False  True  True False False  True  True False  True\n",
            " False  True  True False False False  True  True  True False  True  True\n",
            " False  True  True  True False  True  True False  True  True  True False\n",
            " False  True False  True False  True  True  True  True  True False False\n",
            "  True  True False False False  True  True  True False False False  True\n",
            " False  True False  True  True False False False  True False  True  True\n",
            "  True False  True False  True  True False False  True  True  True False\n",
            " False False  True False False False False False False False  True  True\n",
            " False False  True  True False False  True  True  True  True False  True\n",
            " False False False  True False False False False  True False False False\n",
            "  True  True False False  True False  True False  True False False  True\n",
            " False False False  True  True  True False False False  True  True False\n",
            " False False False  True  True  True False False False  True False False\n",
            "  True False False False False  True False  True False False  True False\n",
            "  True False  True  True  True  True  True False  True False  True False\n",
            "  True False False  True False  True False False  True  True  True  True\n",
            "  True  True  True False False False False  True  True False False  True\n",
            "  True  True  True  True  True False  True  True False False  True False\n",
            "  True  True False False False  True False False  True False  True False\n",
            " False  True  True  True False False  True  True False  True False  True\n",
            "  True False False False  True  True False  True False False False  True\n",
            "  True  True False False False  True False False  True  True  True False\n",
            "  True  True  True False False False False False  True False False  True\n",
            " False  True False  True  True False False False  True False  True False\n",
            "  True False False False  True  True  True  True  True False  True  True\n",
            "  True False  True False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LvgoOWGsx3D"
      },
      "source": [
        "# Theno NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrO2na6sfBA"
      },
      "source": [
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8baH3jAws2Vy"
      },
      "source": [
        "rng = np.random\n",
        "\n",
        "N = 400 # 데이터 샘플 개수\n",
        "feats = 784\n",
        "D = (rng.randn(N,feats).astype(np.float32), rng.randint(size= N, low=0, high=2).astype(np.float32)) # 가우시안 분포를 따르고 있다. "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np38NZuqs2ZG",
        "outputId": "89d49e18-36f4-4929-a433-45bcd692dee2"
      },
      "source": [
        "D  # 데이터가 400개 있다. "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.04053248,  0.29388663, -2.0541575 , ..., -0.541204  ,\n",
              "          0.4129209 , -1.2160792 ],\n",
              "        [ 0.6095187 , -0.12250273,  0.09482337, ..., -0.71622276,\n",
              "          0.33309984,  0.96734935],\n",
              "        [-1.0497601 , -0.12112553, -0.2279788 , ...,  1.4835162 ,\n",
              "          0.5713736 ,  1.6205382 ],\n",
              "        ...,\n",
              "        [ 1.1706346 ,  1.5497293 , -1.1280118 , ..., -1.626088  ,\n",
              "         -0.78285915, -1.5888183 ],\n",
              "        [ 0.75013286, -0.24697147, -0.56382203, ..., -0.42140374,\n",
              "         -2.8064096 ,  0.17692618],\n",
              "        [-1.4966695 , -0.22030614, -1.7135761 , ...,  0.74454576,\n",
              "         -1.3629646 , -0.49076068]], dtype=float32),\n",
              " array([1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
              "        1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
              "        0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
              "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
              "        1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
              "        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
              "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
              "        1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
              "        1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS2-JPYOs4-p",
        "outputId": "f2725b7e-c04d-4940-bafb-fcdb03553b50"
      },
      "source": [
        "training_steps = 10000 \n",
        "x = T.matrix('x') # 데이터의 특징 모델의 입력이 되는 특징값\n",
        "y = T.vector('y') # 각 데이터의 레이블 출력값 \n",
        "# 다층 퍼셉트론은 지도학습 \n",
        "\n",
        "# 모델의 파라미터 \n",
        "# 입력과 출력에 대한 가중치 \n",
        "w_1 = theano.shared(rng.randn(784, 300), name ='w1')\n",
        "b_1 = theano.shared(np.zeros(300), name='b1')\n",
        "w_2 = theano.shared(rng.randn(300), name ='w2')\n",
        "b_2 = theano.shared(0., name='b2') # 1차원 0 아니면 1 300크기의 vector가 되고 bias 는 scaler값이 된다. \n",
        "\n",
        "print(w_1.get_value(), b_1.get_value())\n",
        "print(w_2.get_value(), b_2.get_value())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.3771256  -0.9168258   0.28863033 ...  0.26997819  0.42068167\n",
            "  -0.09575598]\n",
            " [ 0.05342476 -0.64051155 -0.98984561 ... -0.06810666 -0.28743888\n",
            "   0.71269452]\n",
            " [ 0.40654708 -0.70921945 -0.4493909  ...  2.58193993  0.84866398\n",
            "  -0.77114531]\n",
            " ...\n",
            " [-0.52224931  1.78441713  1.80471763 ... -0.77032067 -0.87722737\n",
            "  -0.98664101]\n",
            " [-2.14879229  0.66364641  0.87073539 ...  0.99902463  2.78595065\n",
            "   0.70625223]\n",
            " [ 0.942518   -0.21158024  1.63705651 ... -0.43630103 -1.17875206\n",
            "  -0.1087158 ]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[ 0.0835125  -0.93292562 -0.0792154   0.75217248 -0.91105366  0.06194598\n",
            " -1.4813826  -0.51322387  0.09128732 -2.15498296 -0.53165449  0.55375445\n",
            "  0.52271798  0.5260516  -1.44565859 -0.04530907  0.12005123  0.30381851\n",
            " -0.93204007  1.36771505  0.12903229  0.81350113 -0.75181077  0.48624581\n",
            " -1.38129624  1.2664609  -0.61977415 -0.41369924 -0.20019042  0.11494898\n",
            " -0.24009264  1.55897066  0.95200983  0.08418343 -0.50971664 -0.51270931\n",
            " -1.06756595  0.68678703  0.77604629  0.29257368 -0.47327581 -0.78199559\n",
            " -2.6945289  -0.44173597  0.02475517 -0.31068693 -1.28907724 -0.91357554\n",
            "  0.19406646  1.20885309  0.94916237 -1.30397201 -0.17779753 -1.51996236\n",
            " -0.38664284 -0.94442229  2.76044228  0.59432976  1.71816414 -0.43598682\n",
            "  1.63347557 -0.05214516  0.41214818  0.45913119  0.73791167 -1.29643627\n",
            "  1.01631355 -2.72101475  0.95245444  0.84383268 -0.05320257 -0.57022521\n",
            "  2.0959948   1.52058361 -0.89172865 -0.48084755 -0.03203852 -1.26214766\n",
            "  0.50189035  0.02029708 -0.47952644  0.84651372 -1.8609056  -0.27170225\n",
            "  0.24902184 -0.87341103 -0.40591704 -2.38349991  1.16256391  0.33142649\n",
            " -0.64157626 -0.15312875  0.30054035 -0.97434132  0.99211375 -1.44007269\n",
            " -0.02680552  0.06510926 -0.76635813  1.3271602   1.50788308 -0.21886573\n",
            "  1.43269827 -0.71028507 -1.35902918  0.46456616  1.9765923   0.40896488\n",
            " -0.41512587 -0.17591553  1.44642077 -1.73679717  0.11834051  0.05757777\n",
            "  0.26436399 -0.38284447 -1.66890491  0.17588625 -0.74640449 -0.66409596\n",
            "  0.31974403 -0.74433707 -0.70059617 -0.63125485  0.11513533 -1.14587376\n",
            "  1.48114115  1.01323824 -1.78232323 -0.33201118 -1.37250274 -0.54930426\n",
            " -0.89457652  1.4182542  -1.33097451  0.21632417  0.20610737  0.63179746\n",
            "  1.01336308  0.14938148 -0.86018556  0.91215262  0.98293339 -0.76099523\n",
            " -0.64266345 -0.18049586  0.51356557 -0.32800375 -0.11879911  0.18187756\n",
            " -0.85906467 -0.0752098  -0.31393226  1.45524517 -0.58218508  0.54864422\n",
            " -0.41313099 -0.81356305  0.65189102  0.50361407 -1.77248436 -0.53219195\n",
            "  0.00505253  0.774373   -0.65720195  0.79465746 -1.44407098 -1.05637418\n",
            "  0.60934941  1.12058174  0.14757066 -0.92358064  0.23204987  0.02149688\n",
            "  0.85598703 -0.89044189  0.20209564 -1.33500058 -1.57031132  2.71254484\n",
            " -0.2631902   0.06294019  0.3864217  -1.22213359  0.28825594 -0.0713347\n",
            " -0.87305117 -0.64407461  0.43104973  1.60371898  1.48643573  0.80996877\n",
            " -0.73315422  0.58672646 -0.88050122  1.25590071 -1.41721104 -0.0241494\n",
            "  0.09817625 -0.45957435 -1.68149832 -0.28899483 -0.31538849 -0.79576133\n",
            "  1.42259766 -0.25529679  0.66370028 -0.65310096  0.71330061 -0.39113464\n",
            "  0.21536194  0.25321872 -1.06600633  0.50910381 -1.61814076 -1.52286516\n",
            " -1.8452376   1.185983    0.88880517 -0.04119852  0.61967782  0.57571166\n",
            " -0.3605337  -0.46075762  0.4709485  -1.35947031 -1.12195742  0.47237701\n",
            " -0.7218258   0.63442828 -1.84041236  0.9754427  -1.47528097 -2.58382643\n",
            " -2.40788507  0.30431683  0.53148646 -0.2851759  -2.05440577  0.54463169\n",
            "  1.06290453  0.17807748 -0.76340757 -0.75828349  0.4190312   0.05860824\n",
            " -0.12496751 -2.00022868  0.60386319  0.50525931  0.2811716   0.32769685\n",
            "  1.24525515 -1.84726275  0.38289903  1.27397007  1.16210871 -0.03648759\n",
            "  0.35965929 -0.31093326 -1.36325485  1.11810804 -0.48911397  1.29547824\n",
            " -0.89440251  1.58167785  0.58556458 -0.65365718  0.62979776 -1.94270866\n",
            "  0.71788289  0.65275284  0.84613127 -1.80394598 -0.14350886 -1.2110984\n",
            " -1.82018983 -0.30537632 -1.13197984 -0.20781696  0.35841022  0.0795567\n",
            " -0.43319715  2.41051593  1.49209561  0.95106712  1.75695388  0.41471924\n",
            " -1.54584851  2.25697793 -1.00013539  0.40297378  1.13087461 -0.25314034\n",
            "  0.03344537  1.9663656  -0.47679793 -0.52037985 -1.45343248 -1.38246322] 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpSUgMj9s5Bw"
      },
      "source": [
        "p_1 = T.nnet.sigmoid(T.dot(T.nnet.sigmoid(T.dot(x,w_1)+b_1), w_2) +b_2)\n",
        "prediction = p_1 >0.5\n",
        "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # cross entropy\n",
        "cost = xent.mean() + 0.01 * ( (w_1 ** 2).sum()+ (w_2 ** 2).sum() +(b_1 ** 2).sum() + (b_2 ** 2).sum()) # regularization 파라미터가 크지 않도록 결정을 한다.\n",
        "gw_1,gb_1, gw_2, gb_2 = T.grad(cost,[w_1,b_1,w_2,b_2]) # 손실 함수에 대한 파라미터 의 변화량  미분을 한다. 각각의 파라미터에 대해서 미분"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr9yufDls5Ez",
        "outputId": "d9d0949d-2bcf-49a5-9f5c-13701c394da4"
      },
      "source": [
        "train = theano.function(inputs=[x,y], \n",
        "                        outputs=[prediction, xent], \n",
        "                        updates = {w_1:w_1-0.1*gw_1, b_1:b_1-0.1*gb_1,\n",
        "                                   w_2:w_2-0.1*gw_2, b_2: b_2- 0.1*gb_2}) # 학습률 0.1   updates gpu 에 있는 값 변경 \n",
        "\n",
        "predict = theano.function(inputs=[x], outputs=prediction)\n",
        "# 예측 함수 "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The parameter 'updates' of theano.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (collections.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCcQDRbPvepY",
        "outputId": "9f6e8f4c-dc5e-4dbf-945a-ae8e1f9767ee"
      },
      "source": [
        "for i in range(training_steps):\n",
        "    pred, err = train(D[0], D[1]) # D[0] 데이터의 특징 D[1] l레이블 값\n",
        "\n",
        "print(\"Final model:\")\n",
        "print(w_1.get_value(), b_1.get_value())\n",
        "print(w_2.get_value(), b_2.get_value())\n",
        "print(\"target values for D:\", D[1]) # 실제값\n",
        "print(\"predictions on D:\", predict(D[0])) # 모델의 예측값 "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final model:\n",
            "[[ 2.69487813e-03  4.50974859e-03  4.38467800e-03 ... -1.15074483e-03\n",
            "   1.91808508e-03  7.83158660e-03]\n",
            " [-2.30308892e-04 -3.88117370e-04 -3.77120352e-04 ...  9.80525143e-05\n",
            "  -1.63627469e-04 -6.91505346e-04]\n",
            " [ 1.15487243e-03  1.94644236e-03  1.89132679e-03 ... -4.91511918e-04\n",
            "   8.20353168e-04  3.45266651e-03]\n",
            " ...\n",
            " [ 2.68188224e-03  4.48657986e-03  4.36226480e-03 ... -1.14537235e-03\n",
            "   1.90900790e-03  7.78442625e-03]\n",
            " [-1.44295082e-03 -2.43184092e-03 -2.36299128e-03 ...  6.14139689e-04\n",
            "  -1.02499263e-03 -4.31286566e-03]\n",
            " [-1.90943958e-04 -3.21171947e-04 -3.12129408e-04 ...  8.13401049e-05\n",
            "  -1.35713551e-04 -5.65867304e-04]] [ 1.35619210e-05  8.14562475e-05  7.43649537e-05 -1.00620786e-06\n",
            "  1.87615774e-04 -4.15232026e-05  5.44225997e-04  1.22855860e-06\n",
            "  2.50184751e-04  6.28446451e-04 -8.08906090e-07 -4.99472283e-05\n",
            "  4.22717427e-06  1.32857743e-06  5.79805327e-04  7.91318346e-08\n",
            " -4.73984476e-04 -9.71066924e-05  5.43227705e-04 -8.35566083e-04\n",
            " -2.99374373e-04  3.60886525e-06  1.44953421e-05 -1.14037576e-06\n",
            "  9.45557632e-04 -3.26903210e-04 -2.31097717e-07  1.28375653e-03\n",
            " -5.23746660e-06 -1.45937288e-04  3.22863123e-08 -4.20384192e-04\n",
            " -1.08049438e-04  3.42622424e-07  7.60911599e-06  1.45866928e-04\n",
            "  7.18312851e-04 -3.60152685e-05  3.64362447e-05 -2.60877900e-04\n",
            " -8.57957111e-07  9.71060577e-05  3.00136872e-04 -1.30906339e-06\n",
            "  1.40071549e-04 -8.41078362e-08  5.69581099e-04  1.51002247e-04\n",
            " -4.46157676e-04 -3.01403309e-04 -9.40509839e-05  4.96875077e-05\n",
            "  1.03491892e-06  6.74322349e-04  4.68016991e-05  6.18518518e-05\n",
            " -1.20150951e-03 -6.62048212e-04 -6.82866346e-05 -2.85044802e-05\n",
            " -1.12250728e-03  1.23087399e-06 -1.06416560e-05  6.97425693e-06\n",
            "  1.21393166e-06  3.49828688e-04 -5.10044659e-05  7.65939496e-04\n",
            " -7.22386590e-05 -1.45341076e-04  3.81619090e-04  7.64375593e-05\n",
            " -1.09995205e-03 -5.53529771e-04  1.94599463e-04  7.62757180e-05\n",
            " -1.58368067e-04  2.58810825e-04 -1.04083492e-04  3.26121868e-04\n",
            "  5.89736926e-06 -2.30486469e-04  4.18565268e-04  5.24075302e-05\n",
            "  2.18149619e-07  8.10008239e-04 -2.37143833e-06  1.03258520e-03\n",
            " -3.54611094e-04  2.67270460e-06  9.64077879e-05  4.05768049e-05\n",
            " -9.32866535e-06  8.00178833e-05 -2.80990591e-04  9.64339492e-05\n",
            "  1.88032949e-04  1.32835507e-06 -9.55200016e-07 -2.52810996e-04\n",
            " -1.12948083e-03 -1.94006774e-04 -9.95899431e-04  1.39598602e-04\n",
            "  9.13725359e-04 -1.41360839e-04 -3.51049977e-04  2.73118769e-05\n",
            "  7.32912162e-07  3.36488373e-04 -3.78057619e-05  4.48081127e-04\n",
            "  1.09342075e-06 -4.45840791e-04 -3.51683545e-06 -4.92115907e-07\n",
            "  3.25409814e-04 -1.72348870e-08  6.83019918e-05  3.00341578e-05\n",
            " -1.76956935e-04  1.32804281e-06  5.99884464e-04 -1.26873695e-06\n",
            "  3.76078941e-07  7.67802455e-05 -5.03807551e-05  3.40445659e-09\n",
            "  7.36248468e-04  2.20771901e-04  2.91518412e-05  4.14097910e-04\n",
            "  8.16318175e-05 -1.43972590e-03  8.49256524e-06 -6.67857553e-07\n",
            " -5.78020132e-05 -2.25050321e-04 -4.43930170e-04 -2.74612293e-05\n",
            " -3.07626175e-05 -8.05675639e-04 -9.41194895e-05  1.14937016e-03\n",
            "  4.29555121e-05 -2.04130660e-05 -1.48861819e-04  9.34822391e-07\n",
            "  1.19782953e-04 -8.05452560e-06  7.13527589e-04  1.08380405e-05\n",
            "  4.16195777e-04 -8.33147719e-04  2.93605927e-05  2.17119971e-04\n",
            "  9.09528108e-07 -1.30466718e-06 -1.36219449e-04 -6.92946294e-04\n",
            "  6.57943923e-04  4.56389941e-04 -1.10088527e-04 -1.14013171e-04\n",
            " -6.56408483e-07 -3.13730273e-04 -2.52756055e-05  1.73723041e-04\n",
            " -3.71152536e-04 -8.04166518e-04 -5.32681464e-05  1.12453291e-03\n",
            " -7.19549177e-05 -1.43385153e-05 -4.98425559e-04  1.25642633e-05\n",
            " -6.51871413e-06  8.71524992e-05  5.77109965e-04 -1.00414579e-03\n",
            "  1.13322623e-06  5.12177377e-05  5.30672796e-07  5.06574941e-04\n",
            " -8.08083155e-07  1.86742470e-04  1.33806573e-04  1.49343665e-04\n",
            " -8.36327815e-04 -8.16891144e-04 -8.37662782e-04 -9.02646820e-04\n",
            "  7.60389547e-05  6.83594884e-07  4.15506594e-04 -8.18148659e-04\n",
            "  3.95492089e-04  2.20479968e-06 -3.21953039e-05  1.28256462e-04\n",
            "  1.85223600e-04  8.14296790e-05 -4.38850032e-07  1.69625239e-07\n",
            " -6.86384879e-04  5.05302659e-05 -9.62578649e-04  2.19073638e-05\n",
            " -1.07549401e-03  5.65482774e-07 -2.86498672e-04 -6.11541057e-04\n",
            "  1.87719667e-04 -5.09158634e-04  1.03840193e-04  2.26206741e-06\n",
            "  4.14381018e-04 -4.48936876e-05 -3.29287305e-04  1.62943701e-05\n",
            "  5.88917281e-06 -1.29825340e-06 -2.63737477e-04  1.13781498e-03\n",
            " -1.95701441e-04  1.32748749e-06  3.41477893e-04 -1.19737088e-04\n",
            "  1.22750157e-05  2.12412063e-08  5.22219408e-04  1.29710415e-06\n",
            "  8.24179765e-04  1.36016202e-05  1.21694468e-03  4.62526042e-04\n",
            " -4.83855286e-05 -7.13740598e-05  9.78268272e-04 -1.28857040e-03\n",
            " -1.84163889e-04 -2.82428681e-05  8.42939988e-07  2.16982732e-04\n",
            "  7.18081382e-05 -2.73501364e-06  8.19458794e-05  1.09150446e-03\n",
            " -3.68783081e-04 -9.00131079e-06 -1.38961825e-06 -6.11777910e-04\n",
            " -4.33077579e-04  2.19347953e-04 -3.53416250e-06 -8.49267375e-04\n",
            " -3.00304484e-04 -4.98635362e-06 -2.61892566e-04  1.33885227e-04\n",
            "  3.43136464e-04 -7.08857823e-04  7.12724872e-04 -4.66588511e-04\n",
            "  1.25897915e-04 -7.78933075e-04 -3.81122684e-04  2.64467527e-04\n",
            "  9.66209663e-05  7.39926902e-04  8.51445804e-07 -2.01692202e-04\n",
            " -7.84353029e-04  2.67508534e-04 -9.57254901e-05  1.62187665e-04\n",
            "  6.47374896e-05  9.84099185e-06  1.51513350e-03  6.50712589e-05\n",
            " -1.41461432e-04  1.54694618e-04  4.78608710e-04 -5.41290601e-04\n",
            " -5.37067760e-04 -1.64113945e-05 -1.14430545e-03  6.79866011e-06\n",
            "  7.70364104e-05 -7.64320133e-04  5.76250761e-04 -1.91986096e-04\n",
            " -3.64783734e-04  6.03791825e-05 -1.18040373e-04 -1.00312536e-03\n",
            "  8.95813426e-06  1.10147933e-06  2.74531120e-06  4.53014532e-04]\n",
            "[-0.07500408 -0.12592229 -0.12239866  0.04722314 -0.16445128  0.10279134\n",
            " -0.23491901  0.02957326 -0.18078246 -0.24685396 -0.01043707  0.10862219\n",
            " -0.05756219  0.02405763 -0.24008858  0.00104675  0.22434153  0.13334587\n",
            " -0.23477118  0.27286499  0.19217048 -0.05588691 -0.07630995 -0.01635388\n",
            " -0.28473692  0.19790054 -0.0027429  -0.31757359  0.06036371  0.15183682\n",
            "  0.04187988  0.21538439  0.13792418 -0.04370665 -0.06515191 -0.1515407\n",
            " -0.25856736  0.09857421 -0.09863156  0.18357875 -0.03493737 -0.13307124\n",
            " -0.19206318 -0.02221864 -0.1495721  -0.00094192 -0.23862331 -0.15324425\n",
            "  0.21977358  0.19260368  0.13201009 -0.10817513  0.01429843 -0.25295103\n",
            " -0.10624454 -0.11562969  0.31036108  0.25161137  0.11948279  0.09213377\n",
            "  0.3028995   0.02951473  0.07084137 -0.06388221 -0.04780148 -0.20217871\n",
            "  0.10931007 -0.26442064  0.12157661  0.15163679 -0.20819001 -0.12344943\n",
            "  0.30071403  0.23655755 -0.16642885 -0.12336796  0.15589828 -0.18282513\n",
            "  0.13630005 -0.19747245 -0.06158474  0.17621933 -0.2147997  -0.1099325\n",
            "  0.00274805 -0.26964626  0.05240823 -0.29376342  0.20337346 -0.05308991\n",
            " -0.13276816 -0.10181395  0.0686213  -0.12522331  0.18815911 -0.1327798\n",
            " -0.16457059  0.02392314 -0.03378946  0.18167998  0.30357017  0.16653448\n",
            "  0.29027874 -0.14940922 -0.2813139   0.15028713  0.20268527 -0.09073969\n",
            "  0.03658646 -0.19955545  0.09998575 -0.21982661 -0.04729076  0.21972073\n",
            "  0.0559243   0.04480273 -0.19732785 -0.0416444  -0.11921554 -0.09324265\n",
            "  0.16161399  0.02482867 -0.24292147 -0.02784276 -0.04388414 -0.12362162\n",
            "  0.10890566  0.04205608 -0.2607981  -0.17346858 -0.09244716 -0.21402029\n",
            " -0.12600706  0.3312957  -0.06682981 -0.00840023  0.11353401  0.17483986\n",
            "  0.21940067  0.09116111  0.09416841  0.26940541  0.13204007 -0.30520642\n",
            " -0.10355315  0.08392122  0.15281141 -0.04659458 -0.14224767  0.06629865\n",
            " -0.25796666 -0.07087427 -0.21438672  0.27258793 -0.09263654 -0.17251889\n",
            "  0.03472342 -0.02615622  0.14850831  0.25562091 -0.25080395 -0.22120483\n",
            "  0.13874482  0.14029776 -0.03694488  0.19519769  0.08904848 -0.16037539\n",
            "  0.20651538  0.26922882  0.11075343 -0.30283143  0.12142881  0.0763774\n",
            "  0.22821995 -0.07355031  0.06322497 -0.12861654 -0.23970384  0.29112837\n",
            "  0.0162704  -0.10917092  0.03837128 -0.22921939 -0.01042345 -0.16420072\n",
            " -0.14738577 -0.15269798  0.27295214  0.27071224  0.27310474  0.28037088\n",
            " -0.12324872  0.03704876 -0.21426663  0.27085823 -0.21071638 -0.05154211\n",
            "  0.09541245 -0.14539444 -0.16376329 -0.12590967 -0.00535243  0.04100329\n",
            "  0.25477869 -0.1087257   0.28680358 -0.08528653  0.29831453  0.03808324\n",
            "  0.18937752  0.24480679 -0.16448088  0.22988646 -0.13592519 -0.05173822\n",
            " -0.21406968  0.10520471  0.1983824  -0.0786968  -0.06156619 -0.02146487\n",
            "  0.18424293 -0.30410527  0.1670085   0.0236864  -0.20054404  0.1425037\n",
            " -0.07311744  0.00034361 -0.23161806  0.0211926  -0.2712908  -0.07506038\n",
            " -0.31152311 -0.22221268  0.10758973  0.12112479 -0.2881844   0.3182646\n",
            "  0.16372867  0.09189191 -0.04617807 -0.17248314 -0.12107669  0.05358772\n",
            " -0.12615855 -0.2996253   0.20607082  0.06804196  0.04882881  0.24483935\n",
            "  0.21756623 -0.17309922  0.05597374  0.2744262   0.19236915  0.05976392\n",
            "  0.18381497 -0.14741323 -0.20087069  0.25764421 -0.25786565  0.22314389\n",
            " -0.14453201  0.26624531  0.20836769 -0.18414123 -0.13286073 -0.26125159\n",
            "  0.01122199  0.16866381  0.26689079 -0.18484176  0.13274537 -0.15683326\n",
            " -0.11726122 -0.06922036 -0.33724799 -0.1174469   0.15032149 -0.15444688\n",
            " -0.22481635  0.23475113  0.23412199  0.07912999  0.30498773 -0.06352072\n",
            " -0.12374938  0.26449109 -0.23958095  0.16596574  0.20531619 -0.1147784\n",
            "  0.14185704  0.29102349 -0.06767666  0.0321045  -0.05331966 -0.22064678] 0.00033256806896117693\n",
            "target values for D: [1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
            "predictions on D: [ True False False False False False  True  True  True  True  True False\n",
            " False False False  True False  True False False False False  True  True\n",
            " False  True False  True  True  True False False  True False False False\n",
            " False  True  True False False  True False  True False  True  True  True\n",
            " False  True False False  True False  True  True False  True  True False\n",
            "  True  True  True False False False  True  True False  True  True False\n",
            " False  True False  True  True  True False False False  True  True False\n",
            "  True False  True  True False False  True False False  True False False\n",
            "  True False  True  True False False  True  True  True False False False\n",
            "  True False  True False  True False False False False  True False False\n",
            " False False False False  True False  True  True  True False False False\n",
            "  True  True  True False  True  True False  True False False False  True\n",
            " False False False False False  True  True False False False  True False\n",
            "  True  True  True False  True False False  True  True  True False  True\n",
            " False False False False  True  True  True False  True False False  True\n",
            "  True False  True False  True  True False False  True False False  True\n",
            " False  True False  True False False  True False False  True  True  True\n",
            "  True  True  True False False False  True  True False False  True False\n",
            " False  True  True  True  True False False False  True  True  True  True\n",
            "  True False False  True  True  True  True False False  True False  True\n",
            "  True False False False False False False  True False False False  True\n",
            "  True False False  True  True False False  True  True  True  True False\n",
            "  True  True  True  True  True False False  True False False False  True\n",
            " False  True False  True False False  True  True  True  True  True  True\n",
            "  True False False False False False False  True  True  True False  True\n",
            " False False  True  True  True  True  True  True  True False  True False\n",
            " False False False  True  True False  True False False  True  True  True\n",
            "  True False False  True  True False False  True False False  True  True\n",
            " False  True  True False False False False False  True False False  True\n",
            "  True False False False  True  True False False False False False  True\n",
            "  True  True  True  True  True False  True  True  True False  True  True\n",
            " False  True  True False False False False  True False False False  True\n",
            " False  True  True  True False  True False  True False  True False  True\n",
            " False  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7uouw9Gvwpm",
        "outputId": "d3617423-eb3b-4db5-8190-782480b18067"
      },
      "source": [
        "# accuracy\n",
        "print(np.float(np.sum(D[1]==predict(D[0]))) / np.float(400))\n",
        "# 데이터를 random으로 생성해서 결과가 별로 좋지 않다."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}